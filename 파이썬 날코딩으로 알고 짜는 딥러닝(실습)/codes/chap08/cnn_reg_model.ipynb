{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.3"},"colab":{"name":"cnn_reg_model.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2LL6TVzIeFu","executionInfo":{"status":"ok","timestamp":1623852197894,"user_tz":-540,"elapsed":14097,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}},"outputId":"a381d7c7-1dc3-4620-a82b-8117891543a3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mCOQBzGIaxE","executionInfo":{"status":"ok","timestamp":1623852229847,"user_tz":-540,"elapsed":2497,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}},"outputId":"ac6a2d98-55ad-4ad6-e4e9-3954dab9fc9d"},"source":["%run \"/content/drive/MyDrive/Colab Notebooks/Academy.ALZZA-master/Academy.ALZZA-master/codes/chap07/cnn_basic_model.ipynb\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lM6HO8KlIaxH"},"source":["class CnnRegModel(CnnBasicModel):\n","    def __init__(self, name, dataset, hconfigs, show_maps=False, \n","                 l2_decay=0, l1_decay=0):\n","        self.l2_decay = l2_decay\n","        self.l1_decay = l1_decay\n","        super(CnnRegModel, self).__init__(name, dataset, hconfigs, show_maps)\n","        \n","    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n","                 report=0, show_cnt=3, show_params=False):\n","        super(CnnRegModel, self).exec_all(epoch_count, batch_size, \n","                                     learning_rate, report, show_cnt)\n","        if show_params: self.show_param_dist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxuR5XOAIaxI"},"source":["def cnn_reg_show_param_dist(self):\n","    params = self.collect_params()\n","    mu = np.mean(params)\n","    sigma = np.sqrt(np.var(params))\n","    plt.hist(params, 100, density=True, facecolor='g', alpha=0.75)\n","    plt.axis([-0.2, 0.2, 0, 20.0])\n","    plt.text(0.08, 15.0, 'mu={:5.3f}'.format(mu))\n","    plt.text(0.08, 13.0, 'sigma={:5.3f}'.format(sigma))\n","    plt.grid(True)\n","    plt.show()\n","    \n","    total_count = len(params)\n","    near_zero_count = len(list(x for x in params if -1e-5 <= x <= 1e-5))\n","    print('Near 0 parameters = {:4.1f}%({}/{})'.\n","        format(near_zero_count/total_count*100, near_zero_count, total_count))\n","\n","def cnn_reg_collect_params(self):\n","    params = list(self.pm_output['w'].flatten())\n","    for pm in self.pm_hiddens:\n","        if 'w' in pm: params += list(pm['w'].flatten())\n","        if 'k' in pm: params += list(pm['k'].flatten())\n","    return params\n","\n","CnnRegModel.show_param_dist = cnn_reg_show_param_dist\n","CnnRegModel.collect_params = cnn_reg_collect_params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHHdEoLiIaxI"},"source":["def cnn_reg_forward_extra_cost(self, y):\n","    extra, aux_extra = super(CnnRegModel, self).forward_extra_cost(y)\n","    if self.l2_decay > 0 or self.l1_decay > 0:\n","        params = self.collect_params()\n","        if self.l2_decay > 0:\n","            extra += np.sum(np.square(params)) / 2\n","        if self.l1_decay > 0:\n","            extra += np.sum(np.abs(params))\n","    return extra, aux_extra\n","\n","CnnRegModel.forward_extra_cost = cnn_reg_forward_extra_cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXzayXoaIaxJ"},"source":["def cnn_reg_update_param(self, pm, key, delta):\n","    if self.use_adam:\n","        delta = self.eval_adam_delta(pm, key, delta)\n","\n","    if key in ['w', 'k']:\n","        if self.l2_decay > 0:\n","            delta += self.l2_decay * pm[key] \n","        if self.l1_decay > 0:\n","            delta += self.l1_decay * np.sign(pm[key])\n","\n","    pm[key] -= self.learning_rate * delta\n","        \n","CnnRegModel.update_param = cnn_reg_update_param"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqHBpo4YIaxJ"},"source":["def cnn_reg_alloc_dropout_layer(self, input_shape, hconfig):\n","    keep_prob = get_conf_param(hconfig, 'keep_prob', 1.0)\n","    assert keep_prob > 0 and keep_prob <= 1\n","    return {'keep_prob':keep_prob}, input_shape\n","    \n","def cnn_reg_forward_dropout_layer(self, x, hconfig, pm):\n","    if self.is_training:\n","        dmask = np.random.binomial(1, pm['keep_prob'], x.shape)\n","        dropped = x * dmask / pm['keep_prob']\n","        return dropped, dmask\n","    else:\n","        return x, None\n","\n","def cnn_reg_backprop_dropout_layer(self, G_y, hconfig, pm, aux):\n","    dmask = aux\n","    G_hidden = G_y * dmask / pm['keep_prob']\n","    return G_hidden\n","    \n","CnnRegModel.alloc_dropout_layer = cnn_reg_alloc_dropout_layer\n","CnnRegModel.forward_dropout_layer = cnn_reg_forward_dropout_layer\n","CnnRegModel.backprop_dropout_layer = cnn_reg_backprop_dropout_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKx7U8w9IaxK"},"source":["def cnn_reg_alloc_noise_layer(self, input_shape, hconfig):\n","    noise_type = get_conf_param(hconfig, 'type', 'normal')\n","    mean = get_conf_param(hconfig, 'mean', 0)\n","    std = get_conf_param(hconfig, 'std', 1.0)\n","    ratio = get_conf_param(hconfig, 'ratio', 1.0)\n","\n","    assert noise_type == 'normal'\n","    \n","    return {'mean':mean, 'std':std, 'ratio':ratio}, input_shape\n","    \n","def cnn_reg_forward_noise_layer(self, x, hconfig, pm):\n","    if self.is_training and np.random.rand() < pm['ratio']:\n","        noise = np.random.normal(pm['mean'], pm['std'], x.shape)\n","        return x + noise, None\n","    else:\n","        return x, None\n","\n","def cnn_reg_backprop_noise_layer(self, G_y, hconfig, pm, aux):\n","    return G_y\n","    \n","CnnRegModel.alloc_noise_layer = cnn_reg_alloc_noise_layer\n","CnnRegModel.forward_noise_layer = cnn_reg_forward_noise_layer\n","CnnRegModel.backprop_noise_layer = cnn_reg_backprop_noise_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKl2IV1SIaxK"},"source":["def cnn_reg_alloc_batch_normal_layer(self, input_shape, hconfig):\n","    pm = {}\n","    rescale = get_conf_param(hconfig, 'rescale', True)\n","    pm['epsilon'] = get_conf_param(hconfig, 'epsilon', 1e-10)\n","    pm['exp_ratio'] = get_conf_param(hconfig, 'exp_ratio', 0.001)\n","    \n","    bn_dim = input_shape[-1]\n","    pm['mavg'] = np.zeros(bn_dim)\n","    pm['mvar'] = np.ones(bn_dim)\n","    if rescale:\n","        pm['scale'] = np.ones(bn_dim)\n","        pm['shift'] = np.zeros(bn_dim)\n","    return pm, input_shape\n","    \n","def cnn_reg_forward_batch_normal_layer(self, x, hconfig, pm):\n","    if self.is_training:\n","        x_flat = x.reshape([-1, x.shape[-1]])\n","        avg = np.mean(x_flat, axis=0)\n","        var = np.var(x_flat, axis=0)\n","        pm['mavg'] += pm['exp_ratio'] * (avg - pm['mavg'])\n","        pm['mvar'] += pm['exp_ratio'] * (var - pm['mvar'])\n","    else:\n","        avg = pm['mavg']\n","        var = pm['mvar']\n","    std = np.sqrt(var + pm['epsilon'])\n","    y = norm_x = (x - avg) / std\n","    if 'scale' in pm:\n","        y = pm['scale'] * norm_x + pm['shift']\n","    return y, [norm_x, std]\n","\n","def cnn_reg_backprop_batch_normal_layer(self, G_y, hconfig, pm, aux):\n","    norm_x, std = aux\n","    if 'scale' in pm:\n","        if len(G_y.shape) == 2: axis = 0\n","        else: axis = (0,1,2)\n","        G_scale = np.sum(G_y*norm_x, axis=axis)\n","        G_shift = np.sum(G_y, axis=axis)\n","        G_y = G_y * pm['scale']\n","        pm['scale'] -= self.learning_rate * G_scale\n","        pm['shift'] -= self.learning_rate * G_shift\n","    G_input = G_y / std\n","    return G_input\n","    \n","CnnRegModel.alloc_batch_normal_layer = cnn_reg_alloc_batch_normal_layer\n","CnnRegModel.forward_batch_normal_layer = cnn_reg_forward_batch_normal_layer\n","CnnRegModel.backprop_batch_normal_layer = cnn_reg_backprop_batch_normal_layer"],"execution_count":null,"outputs":[]}]}