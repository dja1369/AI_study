{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.3"},"colab":{"name":"abalone.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltQ-YpyjlhGy","executionInfo":{"status":"ok","timestamp":1619347076983,"user_tz":-540,"elapsed":17214,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}},"outputId":"e2664577-2c2e-4145-ed5e-2bc128aadd9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BUSDTh7lTd1"},"source":["import numpy as np\n","import csv\n","import time\n","\n","np.random.seed(1234)\n","def randomize(): np.random.seed(time.time())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdsLSgk-lTd8"},"source":["RND_MEAN = 0\n","RND_STD = 0.0030\n","\n","LEARNING_RATE = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5CM2CcflTd9"},"source":["def abalone_exec(epoch_count=10, mb_size=10, report=1):\n","    load_abalone_dataset()\n","    init_model()\n","    train_and_test(epoch_count, mb_size, report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdOIkQvilTd9","executionInfo":{"status":"ok","timestamp":1619346790105,"user_tz":-540,"elapsed":555,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}}},"source":["def load_abalone_dataset():\n","    with open('/content/drive/MyDrive/Colab Notebooks/딥러닝/abalone.csv') as csvfile:\n","        csvreader = csv.reader(csvfile)\n","        next(csvreader, None)\n","        rows = []\n","        for row in csvreader:\n","            rows.append(row)\n","            \n","    global data, input_cnt, output_cnt\n","    input_cnt, output_cnt = 10, 1\n","    data = np.zeros([len(rows), input_cnt+output_cnt])\n","\n","    for n, row in enumerate(rows):\n","        if row[0] == 'I': data[n, 0] = 1\n","        if row[0] == 'M': data[n, 1] = 1\n","        if row[0] == 'F': data[n, 2] = 1\n","        data[n, 3:] = row[1:]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"rh-icuKtlTd-"},"source":["def init_model():\n","    global weight, bias, input_cnt, output_cnt\n","    weight = np.random.normal(RND_MEAN, RND_STD,[input_cnt, output_cnt])\n","    bias = np.zeros([output_cnt])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mDNc-_OlTd-"},"source":["def train_and_test(epoch_count, mb_size, report):\n","    step_count = arrange_data(mb_size)\n","    test_x, test_y = get_test_data()\n","    \n","    for epoch in range(epoch_count):\n","        losses, accs = [], []\n","        \n","        for n in range(step_count):\n","            train_x, train_y = get_train_data(mb_size, n)\n","            loss, acc = run_train(train_x, train_y)\n","            losses.append(loss)\n","            accs.append(acc)\n","            \n","        if report > 0 and (epoch+1) % report == 0:\n","            acc = run_test(test_x, test_y)\n","            print('Epoch {}: loss={:5.3f}, accuracy={:5.3f}/{:5.3f}'. \\\n","                  format(epoch+1, np.mean(losses), np.mean(accs), acc))\n","            \n","    final_acc = run_test(test_x, test_y)\n","    print('\\nFinal Test: final accuracy = {:5.3f}'.format(final_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpKcnGrTlTd_"},"source":["def arrange_data(mb_size):\n","    global data, shuffle_map, test_begin_idx\n","    shuffle_map = np.arange(data.shape[0])\n","    np.random.shuffle(shuffle_map)\n","    step_count = int(data.shape[0] * 0.8) // mb_size\n","    test_begin_idx = step_count * mb_size\n","    return step_count\n","\n","def get_test_data():\n","    global data, shuffle_map, test_begin_idx, output_cnt\n","    test_data = data[shuffle_map[test_begin_idx:]]\n","    return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n","\n","def get_train_data(mb_size, nth):\n","    global data, shuffle_map, test_begin_idx, output_cnt\n","    if nth == 0:\n","        np.random.shuffle(shuffle_map[:test_begin_idx])\n","    train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]]\n","    return train_data[:, :-output_cnt], train_data[:, -output_cnt:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"el2bAS9LlTd_"},"source":["def run_train(x, y):\n","    output, aux_nn = forward_neuralnet(x)\n","    loss, aux_pp = forward_postproc(output, y)\n","    accuracy = eval_accuracy(output, y)\n","    \n","    G_loss = 1.0\n","    G_output = backprop_postproc(G_loss, aux_pp)\n","    backprop_neuralnet(G_output, aux_nn)\n","    \n","    return loss, accuracy\n","\n","def run_test(x, y):\n","    output, _ = forward_neuralnet(x)\n","    accuracy = eval_accuracy(output, y)\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuPBaZOslTeA"},"source":["def forward_neuralnet(x):\n","    global weight, bias\n","    output = np.matmul(x, weight) + bias\n","    return output, x\n","\n","def backprop_neuralnet(G_output, x):\n","    global weight, bias\n","    g_output_w = x.transpose()\n","    \n","    G_w = np.matmul(g_output_w, G_output)\n","    G_b = np.sum(G_output, axis=0)\n","\n","    weight -= LEARNING_RATE * G_w\n","    bias -= LEARNING_RATE * G_b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufMif0D5lTeA"},"source":["def forward_postproc(output, y):\n","    diff = output - y\n","    square = np.square(diff)\n","    loss = np.mean(square)\n","    return loss, diff\n","\n","def backprop_postproc(G_loss, diff):\n","    shape = diff.shape\n","    \n","    g_loss_square = np.ones(shape) / np.prod(shape)\n","    g_square_diff = 2 * diff\n","    g_diff_output = 1\n","\n","    G_square = g_loss_square * G_loss\n","    G_diff = g_square_diff * G_square\n","    G_output = g_diff_output * G_diff\n","    \n","    return G_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xErVOqjnlTeA"},"source":["def eval_accuracy(output, y):\n","    mdiff = np.mean(np.abs((output - y)/y))\n","    return 1 - mdiff"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7fDLOWzlTeB"},"source":["def backprop_postproc_oneline(G_loss, diff):  # backprop_postproc() 대신 사용 가능\n","    return 2 * diff / np.prod(diff.shape)"],"execution_count":null,"outputs":[]}]}