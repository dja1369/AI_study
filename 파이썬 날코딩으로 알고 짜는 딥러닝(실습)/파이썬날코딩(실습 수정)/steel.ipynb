{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.3"},"colab":{"name":"steel.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzafhth_oyn7","executionInfo":{"status":"ok","timestamp":1619347605724,"user_tz":-540,"elapsed":16736,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}},"outputId":"aa220edb-d431-4ed6-c189-ed57e246d157"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtnyqM4wowWl","executionInfo":{"status":"ok","timestamp":1619347647732,"user_tz":-540,"elapsed":1397,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}},"outputId":"92f9dc84-4730-4e45-f062-78ede8db5c6d"},"source":["%run '/content/drive/MyDrive/Colab Notebooks/abalone.ipynb'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"96dMj8ymowWs"},"source":["def steel_exec(epoch_count=10, mb_size=10, report=1):\n","    load_steel_dataset()\n","    init_model()\n","    train_and_test(epoch_count, mb_size, report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTOCUy2CowWt","executionInfo":{"status":"ok","timestamp":1619347668737,"user_tz":-540,"elapsed":869,"user":{"displayName":"이덕수","photoUrl":"","userId":"04402217723891097609"}}},"source":["def load_steel_dataset():\n","    with open('/content/drive/MyDrive/Colab Notebooks/딥러닝/faults.csv') as csvfile:\n","        csvreader = csv.reader(csvfile)\n","        next(csvreader, None)\n","        rows = []\n","        for row in csvreader:\n","            rows.append(row)\n","            \n","    global data, input_cnt, output_cnt\n","    input_cnt, output_cnt = 27, 7\n","    data = np.asarray(rows, dtype='float32')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVz8kxg9owWt"},"source":["def forward_postproc(output, y):\n","    entropy = softmax_cross_entropy_with_logits(y, output)\n","    loss = np.mean(entropy) \n","    return loss, [y, output, entropy]\n","\n","def backprop_postproc(G_loss, aux):\n","    y, output, entropy = aux\n","    \n","    g_loss_entropy = 1.0 / np.prod(entropy.shape)\n","    g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n","    \n","    G_entropy = g_loss_entropy * G_loss\n","    G_output = g_entropy_output * G_entropy\n","    \n","    return G_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"waGN29nbowWu"},"source":["def eval_accuracy(output, y):\n","    estimate = np.argmax(output, axis=1)\n","    answer = np.argmax(y, axis=1)\n","    correct = np.equal(estimate, answer)\n","    \n","    return np.mean(correct)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4RVNyVTowWu"},"source":["def softmax(x):\n","    max_elem = np.max(x, axis=1)\n","    diff = (x.transpose() - max_elem).transpose()\n","    exp = np.exp(diff)\n","    sum_exp = np.sum(exp, axis=1)\n","    probs = (exp.transpose() / sum_exp).transpose()\n","    return probs\n","\n","def softmax_derv(x, y):\n","    mb_size, nom_size = x.shape\n","    derv = np.ndarray([mb_size, nom_size, nom_size])\n","    for n in range(mb_size):\n","        for i in range(nom_size):\n","            for j in range(nom_size):\n","                derv[n, i, j] = -y[n,i] * y[n,j]\n","            derv[n, i, i] += y[n,i]\n","    return derv\n","\n","def softmax_cross_entropy_with_logits(labels, logits):\n","    probs = softmax(logits)\n","    return -np.sum(labels * np.log(probs+1.0e-10), axis=1)\n","\n","def softmax_cross_entropy_with_logits_derv(labels, logits):\n","    return softmax(logits) - labels"],"execution_count":null,"outputs":[]}]}