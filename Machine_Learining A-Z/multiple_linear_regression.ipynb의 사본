{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multiple_linear_regression.ipynb의 사본","provenance":[{"file_id":"1VUjzjUoKNR0jKQPzXGxv4KeUh35UR_sN","timestamp":1648171958672}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CazISR8X_HUG"},"source":["# Multiple Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"pOyqYHTk_Q57"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"T_YHJjnD_Tja","executionInfo":{"status":"ok","timestamp":1648176330133,"user_tz":-540,"elapsed":358,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgC61-ah_WIz"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["dataset = pd.read_csv('50_Startups.csv')\n","x = dataset.iloc[:, :-1].values # 모든행 + 마지막열을 제외한 모든열 값을 가져옴\n","y = dataset.iloc[:, -1].values # 모든행 + 마지막 열의 값만 가져옴"],"metadata":{"id":"Tu-Qgy-ct8qk","executionInfo":{"status":"ok","timestamp":1648176330526,"user_tz":-540,"elapsed":7,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VadrvE7s_lS9"},"source":["## Encoding categorical data "]},{"cell_type":"code","metadata":{"id":"wV3fD1mbAvsh","executionInfo":{"status":"ok","timestamp":1648176330527,"user_tz":-540,"elapsed":8,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[3])],remainder='passthrough') # 4번째 열을 선택해야 범주형 데이터를 선택할수있다.\n","x = np.array(ct.fit_transform(x))"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ym3HdYeCGYG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"488809e8-3c61-40f1-ff66-e737e966d9ac","executionInfo":{"status":"ok","timestamp":1648176330527,"user_tz":-540,"elapsed":8,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["print(x)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"WemVnqgeA70k"},"source":["## Splitting the dataset into the Training set and Test set\n","## 훈련용과 검증용으로 데이터셋 분리"]},{"cell_type":"code","metadata":{"id":"Kb_v_ae-A-20","executionInfo":{"status":"ok","timestamp":1648176330528,"user_tz":-540,"elapsed":7,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-McZVsQBINc"},"source":["## Training the Multiple Linear Regression model on the Training set\n","## 다중 선형 회귀 모델 훈련 "]},{"cell_type":"code","metadata":{"id":"ywPjx0L1BMiD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"285f864b-f404-47c5-cba7-ab13a251be5a","executionInfo":{"status":"ok","timestamp":1648176330528,"user_tz":-540,"elapsed":7,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["from sklearn.linear_model import LinearRegression\n","regressor = LinearRegression() # 선형회귀 클래스 선언\n","regressor.fit(x_train, y_train) # .fit메소드를 사용하여 x_train 데이터셋과 y_train 데이터셋 훈련."],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression()"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"OWgUjx3N9oH4"}},{"cell_type":"markdown","metadata":{"id":"xNkXL1YQBiBT"},"source":["## Predicting the Test set results\n","## 검증 결과 예측 "]},{"cell_type":"code","metadata":{"id":"TQKmwvtdBkyb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b968944-03a6-4347-fd4f-5ff820e8a510","executionInfo":{"status":"ok","timestamp":1648176498255,"user_tz":-540,"elapsed":386,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}}},"source":["y_pred = regressor.predict(x_test)\n","np.set_printoptions(precision=2) # 출력의 정밀도 설정 소수점 결정\n","\n","# y_pred 벡터를 len y_pred열이 있는 배열로 재배열 한다는 코드\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[[103015.2  103282.38]\n"," [132582.28 144259.4 ]\n"," [132447.74 146121.95]\n"," [ 71976.1   77798.83]\n"," [178537.48 191050.39]\n"," [116161.24 105008.31]\n"," [ 67851.69  81229.06]\n"," [ 98791.73  97483.56]\n"," [113969.44 110352.25]\n"," [167921.07 166187.94]]\n"]}]},{"cell_type":"markdown","source":["Building the optimal model using Backward Elimination\n","후진 소거법을 이용해 모델 개선"],"metadata":{"id":"1WnDVxy4A4nu"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","x = np.append(arr = np.ones((50,1)).astype(int), values = x, axis =1)\n","x_opt = x[:,[0,1,2,3,4,5]]\n","x_opt = x_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regressor_OLS.summary()\n","x_opt = x[:,[0,1,3,4,5]]\n","x_opt = x_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regressor_OLS.summary()\n","x_opt = x[:,[0,3,4,5]]\n","x_opt = x_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regressor_OLS.summary()\n","x_opt = x[:,[0,3,5]]\n","x_opt = x_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regressor_OLS.summary()\n","x_opt = x[:,[0,3]]\n","x_opt = x_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regressor_OLS.summary()\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"id":"6b5RvhweBBST","executionInfo":{"status":"ok","timestamp":1648177937705,"user_tz":-540,"elapsed":382,"user":{"displayName":"이덕수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402217723891097609"}},"outputId":"8c0118ed-5fc7-4cb1-db1a-ad2029706392"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/regression/linear_model.py:1657: RuntimeWarning: invalid value encountered in double_scalars\n","  return self.ess/self.df_model\n","/usr/local/lib/python3.7/dist-packages/statsmodels/regression/linear_model.py:1657: RuntimeWarning: divide by zero encountered in double_scalars\n","  return self.ess/self.df_model\n"]},{"output_type":"execute_result","data":{"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.000\n","Model:                            OLS   Adj. R-squared:                  0.000\n","Method:                 Least Squares   F-statistic:                       nan\n","Date:                Fri, 25 Mar 2022   Prob (F-statistic):                nan\n","Time:                        03:12:18   Log-Likelihood:                -600.65\n","No. Observations:                  50   AIC:                             1203.\n","Df Residuals:                      49   BIC:                             1205.\n","Df Model:                           0                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       5.601e+04   2850.077     19.651      0.000    5.03e+04    6.17e+04\n","x1          5.601e+04   2850.077     19.651      0.000    5.03e+04    6.17e+04\n","==============================================================================\n","Omnibus:                        0.018   Durbin-Watson:                   0.020\n","Prob(Omnibus):                  0.991   Jarque-Bera (JB):                0.068\n","Skew:                           0.023   Prob(JB):                        0.966\n","Kurtosis:                       2.825   Cond. No.                     5.02e+16\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 3.98e-32. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n","\"\"\""],"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.000</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Fri, 25 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>03:12:18</td>     <th>  Log-Likelihood:    </th> <td> -600.65</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1203.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    49</td>      <th>  BIC:               </th> <td>   1205.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 5.601e+04</td> <td> 2850.077</td> <td>   19.651</td> <td> 0.000</td> <td> 5.03e+04</td> <td> 6.17e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 5.601e+04</td> <td> 2850.077</td> <td>   19.651</td> <td> 0.000</td> <td> 5.03e+04</td> <td> 6.17e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.018</td> <th>  Durbin-Watson:     </th> <td>   0.020</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.991</td> <th>  Jarque-Bera (JB):  </th> <td>   0.068</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 0.023</td> <th>  Prob(JB):          </th> <td>   0.966</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 2.825</td> <th>  Cond. No.          </th> <td>5.02e+16</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.98e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."]},"metadata":{},"execution_count":44}]}]}